{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd6de59",
   "metadata": {},
   "source": [
    "#### Import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dde827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e1768",
   "metadata": {},
   "source": [
    "#### Load yolo weights and cfg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9923008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Yolo weights and config\n",
      "Loaded Yolo weights and config\n"
     ]
    }
   ],
   "source": [
    "weights_path = os.path.join (\"yolo\",\"yolov3.weights\")\n",
    "config_path = os.path.join (\"yolo\",\"yolov3.cfg\")\n",
    "\n",
    "print(\"Loaded Yolo weights and config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc483b61",
   "metadata": {},
   "source": [
    "#### Load the neural net in the cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3a70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(config_path , weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4307b3",
   "metadata": {},
   "source": [
    "#### Get Layer Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c49928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = net.getLayerNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aad415",
   "metadata": {},
   "source": [
    "#### Load test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0b60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join (\"yolo\",\"test1.jpg\")\n",
    "img=cv2.imread(image_path)\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "345d0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(H,W)= img.shape[:2]\n",
    "# layers_names = [names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "layers_names = [names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94e1c78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_82', 'yolo_94', 'yolo_106']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['yolo_82', 'yolo_94', 'yolo_106']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae7944",
   "metadata": {},
   "source": [
    "#### Run the inference on the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0130ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A forward pass through yolov3 took 0.7616486549377441\n",
      "A forward pass through yolov3 took 0.7616486549377441\n"
     ]
    }
   ],
   "source": [
    "blob = cv2.dnn.blobFromImage (img, 1/255.0 , (416,416), crop=False,swapRB=False)\n",
    "net.setInput(blob)\n",
    "#calculate the runtime of the algorithm\n",
    "start_t=time.time()\n",
    "layers_output=net.forward(layers_names)\n",
    "print (\"A forward pass through yolov3 took {}\".format(time.time()- start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23cee892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 85)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(507, 85)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ac0b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes =[]\n",
    "confidences=[]\n",
    "classIDs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a82bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in layers_output:\n",
    "    for detection in output:\n",
    "        scores=detection[5:]\n",
    "        classID = np.argmax(scores)\n",
    "        confidence = scores[classID]\n",
    "        \n",
    "        if confidence > 0.85:\n",
    "            box = detection[:4]*np.array([W,H,W,H])\n",
    "            bx, by, bw, bh = box.astype(\"int\")\n",
    "            \n",
    "            x=int(bx - (bw/2))\n",
    "            y=int(by - (bh/2))\n",
    "            \n",
    "            boxes.append([x,y,int(bw),int(bh)])\n",
    "            confidences.append(float(confidence))\n",
    "            classIDs.append(classID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2184d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = cv2.dnn.NMSBoxes(boxes,confidences,0.8,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be288dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = os.path.join(\"yolo\",\"coco.names\")\n",
    "labels = open(labels_path).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00149755",
   "metadata": {},
   "source": [
    "#### Plot the bounding boxes in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0358861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in idxs.flatten():\n",
    "    (x,y) = [boxes[i][0],boxes[i][1]]\n",
    "    (w,h)=[boxes[i][2],boxes[i][3]]\n",
    "    \n",
    "    cv2.rectangle(img, (x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.putText (img,\"{}:{}\".format(labels[classIDs[i]],confidences[i]),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),2)\n",
    "                 \n",
    "# plt.imshow(img)\n",
    "cv2.imshow(\"Images\",cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
