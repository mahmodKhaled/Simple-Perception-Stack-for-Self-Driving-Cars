# Simple Perception Stack for Self-Driving Cars
In this project we are going to create a **_simple perception stack for self-driving cars_** (SDCs.) Although a typical perception stack for a self-driving car may contain different data sources from different sensors (ex.: cameras, lidar, radar, etc…), we’re only going to be focusing on video streams from cameras for simplicity. We’re mainly going to be analyzing the road ahead, detecting the lane lines, detecting other cars/agents on the road, and estimating some useful information that may help other SDCs stacks. The project is split into two phases. We’ll be going into each of them in the following parts.
## Phase 1 - Lane Line detection
In this first phase, our goal is to write a **_software pipeline_** to identify the lane boundaries in a video from a front-facing camera on a car
### _Expected Output from Phase 1_
![expected output](https://user-images.githubusercontent.com/54672453/163658944-d04f1d58-98ae-4017-b196-ba660c7d4a1b.png)

## Code Status
![Status](https://img.shields.io/badge/Status-not%20finished-red)
